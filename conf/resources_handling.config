params {
    max_attempts = 3
    default_error_strategy = "terminate" // ["retry" or "terminate"]
    // attempt 1 -> y_pred = [(b0 + b0_offset) + b1*x]
    // attempt 2 -> y_pred * f1
    // attempt > 2 -> y_pred + a2
    mem_k2r_b0_offset = 2 // GB
    mem_k2r_b0= 1.23932729 
    mem_k2r_b0_final = params.mem_k2r_b0 + params.mem_k2r_b0_offset
    mem_k2r_b1= 3.57231124
    mem_k2r_f1 = 1.5
    mem_k2r_a2 = 2
}


//memory = check_max( escalate_exp( 4.GB, task, 2 ), 'memory' )
//errorStrategy = { retry_strategy(task, params.max_retries) }

def bytesToSize(bytes, unit) {
    def values = [
        'B' : 1,
        'KB': 1024,
        'MB': 1024 * 1024,
        'GB': 1024 * 1024 * 1024
    ]

    def factor = values.get(unit)
    if (factor == null) {
        throw new Exception("Invalid unit: ${unit}")
    }

    return bytes / factor
}

def linear_regression_fit(x, b0, b1) {
    // y_pred = b0 + b1*x
    return b0 + b1*x
}

def retry_strategy(task, max_attempts, default_error_strategy){
    // this is borrow directly from PAM nextflow commons
    
    //
    def MISC_EXIT_CODES = [
        "SIGKILL": 137,
        "SIGTERM": 143,
        "SIGABRT": 134,
        "SIGSEGV": 139
    ].values()

    def SCALING_EXIT_CODES = [
        
        // see https://ssg-confluence.internal.sanger.ac.uk/pages/viewpage.action?pageId=101361150
        // LSF Runlimit exceeded or Out of memory Error; first signal allowing to quit cleanly
        "SIGUSR2": 140,
        
        // LSF Runlimit exceeded or Out of memory Error or bkill; second signal sent shortly
        // after the SIGUSR2 to make it quit if not done yet
        "SIGINT": 130,
        
        // LSF Runlimit exceeded or Out of memory Error; apparently what LSF issues after a while
        // once the above two signals have been sent and not acted upon. Apparently kills the job
        // instantly so that the exit status has not got time to be written into an .exitcode 
        // file and is not reported to the Nextflow master process - therefore the value 9 is
        // never seen here in practice; see below for actual value.
        // source of issue reported here https://github.com/nextflow-io/nextflow/issues/2847
        "SIGKILLNOW": 9,
        // supposedly the default value of $task.exitStatus; this is what it is set to when not 
        // set in the absence of an .exitcode file for the previous execution of the task, as
        // would happen in the case mentioned above
        "NOEXITCODE": 2147483647 
    ].values()
    
    if (task.attempt > max_attempts) {
        return default_error_strategy
    }
    // ------------------------------------------------- //
    switch(task.exitStatus) {
        // if non scalable error, kill the pipeline without mercy
        case {it in MISC_EXIT_CODES}:
            // Ignore due to non-scalable error code
            return default_error_strategy

        // if scaling related error:
        case {it in SCALING_EXIT_CODES}:
            // Retry with more memory and longer time limit
            return 'retry'

        case {it == null}:
            /*
            If exitStatus is null as is the case on the first attempt return 'retry'
            */
            return 'retry'

        default:
            // Return the value of params.retry_strategy
            return default_error_strategy
    }

}

def k2r_escalate_memory_strategy(task, input_size_GB, b0=params.mem_k2r_b0, b1=params.mem_k2r_b1, f1=params.mem_k2r_f1, a2=params.mem_k2r_a2){
    /**
    * Escalate memory strategy for tasks.
    *
    * This function takes into account the input size in GB and applies a memory escalation strategy based on the task attempt number.
    *
    * The strategy involves linear regression to predict peak memory usage, with adjustments made based on the task attempt number.
    *
    * @param task    The task object
    * @param input_size_GB  The input size in GB
    * @param b0     Coefficient for linear regression
    * @param b1     Coefficient for linear regression
    * @param f1      Factor to multiply predicted peak memory usage (for second attempt)
    * @param a2      Additional memory allocation per attempt (in GB) after the first attempt
    *
    * @return  The escalated memory size in GB, taking into account the task attempt number and input size.
    */

    // predict peak mem
    peak_mem_pred = linear_regression_fit(input_size_GB,b0,b1)
    //println("${peak_mem_pred}, ${input_size_GB}, ${b0}, ${b1}")

    // if second try, add multiply predicted by factor 1 (f1)
    if (task.attempt == 2){
        return "${peak_mem_pred * f1} GB"
    }

    // if second attempt, add a2 gb to previous attempt  
    if (task.attempt == 3){
        return "${(peak_mem_pred * f1) + a2} GB"
    }

    // keep adding a2 gb for each attempt
    if (task.attempt > 3) {
        return "${(peak_mem_pred * f1) + ((task.attempt) * a2)}"
    }

    // if first try, use linear regression
    return "${peak_mem_pred} GB"
}

process {
    errorStrategy = {retry_strategy(task, params.max_attempts, params.default_error_strategy) }
    max_retries = params.max_attempts
    
    withLabel:mem_k2r_escalate{
        //memory = "2 GB"
        
        memory = {k2r_escalate_memory_strategy(
                            task,
                            bytesToSize(meta.fqs_total_size, "GB"),
                            params.mem_k2r_b0_final,
                            params.mem_k2r_b1,
                            params.mem_k2r_f1,
                            params.mem_k2r_a2)}
        
    }
    
}