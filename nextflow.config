// Copyright (C) 2023 Genome Surveillance Unit/Genome Research Ltd.

includeConfig "./conf/containers.config"
includeConfig "./rvi_toolbox/nextflow-commons.config"

manifest {
    name            = 'Viral Lens'
    author          = 'ARD'
    homePage        = 'https://github.com/genomic-surveillance/rvi-viral-lens'
    description     = 'identify the presence of Flu, SARS-CoV-2 and RSV and obtain, if possible, high quality consensus sequences for those virus.'
    mainScript      = 'main.nf'
    nextflowVersion = '>=24.10.3'
    version         = 'v1.2.0'
}

plugins {
  id 'nf-schema@2.2.0'
}

params {

    // -- REQUIRED INPUT --//
    manifest = null

    // kraken database
    db_path = null
    db_library_fa_path = null
    // ---------------------- //

    // --- SET PIPELINE DEFAULT PARAMETERS --//

    // --- general pipeline
    // sets where to find the local containers 
    containers_dir = "$projectDir/containers/"

    // set where output files should be published
    outdir = "$launchDir/results/"

    // scov2 subtyping switchs
    do_scov2_subtyping = true

    // --- SET WORKFLOW SPECIFIC DEFAULT PARAMETERS --- //

    // -- CONSENSUS GENERATION

    // -- SUBTYPING
    // virus subtyping branching keywords
    scv2_keyword = "Severe acute respiratory syndrome coronavirus 2"

    // -- kraken
    kraken2_mem = "2 GB"
    kraken2_cpus = 4

    // -- Kraken2ref (k2r)
    k2r_fq_load_mode = "full"
    k2r_polling_mode = "max"

    // kraken report minum number of reads filter
    min_reads_for_taxid = 100

    // set maximum number of reads to be accepted
    k2r_max_total_reads_per_fq = 10000000
    // any fastq file pair with more than that number of reads
    // will be splitted into N chunks, each containing that maximum
    // amount of reads to be processed by k2r. Those splitted files
    // are intemediate files and the final output will still be per
    // reported per sample. 
    
    // set default value for k2r_dump_fq process
    k2r_dump_fq_mem = "6 GB"

    
    // ---------------------- //
    // -- IVAR 
    ivar_min_depth = 10
    ivar_freq_threshold = 0.75
    // ---------------------- //

    // minimum coverage to be reported
    min_coverage_percent = 10.0

    // debug options
    developer_publish = false
}

// Execution layer settings

process {
    // Set pipelines outputs
    // -- standard outputs
    withLabel: sample_output {
        publishDir = [
            path: {"${params.outdir}/${meta.sample_id}/${meta.taxid}/"},
            overwrite: true,
            mode: "copy",
            pattern:"*{.bam,.bai,.fa}"
        ]
    }

    withLabel: run_output {
        publishDir = [
            path: {"${params.outdir}/"}, 
            overwrite: true,
            mode: "copy"
        ]
    }

    // -- intermediate outputs
    withLabel: get_taxid_reference_files {
        publishDir = [
                enabled: params.developer_publish,
                path: {"${params.outdir}/reference_files/"},
                mode: 'copy'
        ]
    }
    withName: run_pangolin {
        publishDir = [
                enabled: params.developer_publish,
                path: {"${params.outdir}/${meta.sample_id}/${meta.taxid}/"},
                mode: 'copy',
                pattern: "*.csv"
        ]
    }

    withName: run_qc_script {
        publishDir = [
                enabled: params.developer_publish,
                path: {"${params.outdir}/${meta.sample_id}/${meta.taxid}/"},
                mode: 'copy',
        ]
    }

    withLabel: Kraken2ref {
        publishDir = [
                enabled: params.developer_publish,
                path: {"${params.outdir}/${meta.sample_id}/reads_by_taxon/"},
                mode: 'copy',
                pattern: "*.{tsv,fq.json}"
        ]
    }

    withLabel: kraken {
        publishDir = [
                enabled: params.developer_publish,
                path: {"${params.outdir}/${meta.sample_id}/"},
                mode: 'copy'
        ]
    }
}

profiles {
    standard {

        docker {
            enabled = false
        }

        singularity {
            enabled = true
            autoMounts = true
            runOptions = '--writable-tmpfs'
        }

        process {
            // by default nextflow commons (1 cpu, 1GB, 1h)
            cache='lenient'
            executor='local'
        }

    }

    sanger_standard {
        params { 
            // set "sanger specific" parameters
            // General container usage
            use_local_containers = false
            use_registry_containers = true

            // Overwrite nextflow-commons default
            max_retries = 3
            // Max resources a process can request
            max_memory = 128.GB // 2.9.TB
            max_cpus = 32 // 256
            max_time = 6.h // 720.h
        }

        docker {
            enabled = false
        }
        
        singularity {
            enabled = true
            autoMounts = true
            runOptions = "--bind /lustre,/nfs,/software,/data/"

        }

        process {
            // by default nextflow commons (1 cpu, 1GB, 1h)
            cache='lenient'
            executor='local'

            // run k2r on lsf
            withName: run_k2r_sort_reads{
                executor = 'lsf'
                //label = "mem_k2r_escalate"
                queue = 'normal'
            }

            withName: run_k2r_dump_fastqs_and_pre_report{
                executor = 'lsf'
                //label = "mem_k2r_escalate"
                queue = 'normal'
            }

            // run kraken2 on lsf
            withName: run_kraken{
                executor = 'lsf'
                queue = 'normal'
                cpus = "${params.kraken2_cpus}"
                memory = "${params.kraken2_mem}"
            }
            //NOTE: There is room for optimization of the remaining processes
        }
        executor {
            jobName={ "RVI-viral-lens - $task.name - $task.tag" }
            perJobMemLimit=true

        }
    }


    sanger_local_farm {
        // this profile is used to run the pipeline on a single node of the farm
        // without spawning multiple jobs on the LSF cluster.
        // it is not recommended to use this profile for large datasets
        params {
            // set "sanger specific" parameters
            // General container usage
            use_local_containers = false
            use_registry_containers = true

            // Overwrite nextflow-commons default
            max_retries = 3
            // Max resources a process can request
            max_memory = 128.GB // 2.9.TB
            max_cpus = 32 // 256
            max_time = 6.h // 720.h
        }

        docker {
            enabled = false
        }
        
        singularity {
            enabled = true
            autoMounts = true
            runOptions = "--bind /lustre,/nfs,/software,/data/"
        }

        process {
            // by default nextflow commons (1 cpu, 1GB, 1h)
            cache='lenient'
            executor='local'

            withName: run_kraken {
                executor = 'local'
                cpus = "${params.kraken2_cpus}"
                memory = "${params.kraken2_mem}"
            }
        }
    }
}

//---| memory escalation for k2r_sort_reads |

params {
    max_attempts = 3
    default_error_strategy = "terminate" // ["retry" or "terminate"]
    // attempt 1 -> y_pred = [(b0 + b0_offset) + b1*x]
    // attempt 2 -> y_pred * f1
    // attempt > 2 -> y_pred + a2
    mem_k2r_b0_offset = 2 // GB
    mem_k2r_b0= 1.23932729 
    mem_k2r_b0_final = params.mem_k2r_b0 + params.mem_k2r_b0_offset
    mem_k2r_b1= 3.57231124
    mem_k2r_f1 = 1.5
    mem_k2r_a2 = 2
}

def bytesToSize(bytes, unit) {
    def values = [
        'B' : 1,
        'KB': 1024,
        'MB': 1024 * 1024,
        'GB': 1024 * 1024 * 1024
    ]

    def factor = values.get(unit)
    if (factor == null) {
        throw new Exception("Invalid unit: ${unit}")
    }

    return bytes / factor
}

def linear_regression_fit(x, b0, b1) {
    // y_pred = b0 + b1*x
    return b0 + b1*x
}

def retry_strategy(task, max_attempts, default_error_strategy){
    // this is borrow directly from PAM nextflow commons
    //
    def MISC_EXIT_CODES = [
        "SIGKILL": 137,
        "SIGTERM": 143,
        "SIGABRT": 134,
        "SIGSEGV": 139
    ].values()

    def SCALING_EXIT_CODES = [
        // see https://ssg-confluence.internal.sanger.ac.uk/pages/viewpage.action?pageId=101361150
        // LSF Runlimit exceeded or Out of memory Error; first signal allowing to quit cleanly
        "SIGUSR2": 140,

        // LSF Runlimit exceeded or Out of memory Error or bkill; second signal sent shortly
        // after the SIGUSR2 to make it quit if not done yet
        "SIGINT": 130,

        // LSF Runlimit exceeded or Out of memory Error; apparently what LSF issues after a while
        // once the above two signals have been sent and not acted upon. Apparently kills the job
        // instantly so that the exit status has not got time to be written into an .exitcode 
        // file and is not reported to the Nextflow master process - therefore the value 9 is
        // never seen here in practice; see below for actual value.
        // source of issue reported here https://github.com/nextflow-io/nextflow/issues/2847
        "SIGKILLNOW": 9,
        // supposedly the default value of $task.exitStatus; this is what it is set to when not 
        // set in the absence of an .exitcode file for the previous execution of the task, as
        // would happen in the case mentioned above
        "NOEXITCODE": 2147483647 
    ].values()
    
    if (task.attempt > max_attempts) {
        return default_error_strategy
    }
    // ------------------------------------------------- //
    switch(task.exitStatus) {
        // if non scalable error, kill the pipeline without mercy
        case {it in MISC_EXIT_CODES}:
            // Ignore due to non-scalable error code
            return default_error_strategy

        // if scaling related error:
        case {it in SCALING_EXIT_CODES}:
            // Retry with more memory and longer time limit
            return 'retry'

        case {it == null}:
            /*
            If exitStatus is null as is the case on the first attempt return 'retry'
            */
            return 'retry'

        default:
            // Return the value of params.retry_strategy
            return default_error_strategy
    }

}

def k2r_escalate_memory_strategy(task, input_size_GB, b0=params.mem_k2r_b0, b1=params.mem_k2r_b1, f1=params.mem_k2r_f1, a2=params.mem_k2r_a2){
    /**
    * Escalate memory strategy for tasks.
    *
    * This function takes into account the input size in GB and applies a memory escalation strategy based on the task attempt number.
    *
    * The strategy involves linear regression to predict peak memory usage, with adjustments made based on the task attempt number.
    *
    * @param task    The task object
    * @param input_size_GB  The input size in GB
    * @param b0     Coefficient for linear regression
    * @param b1     Coefficient for linear regression
    * @param f1      Factor to multiply predicted peak memory usage (for second attempt)
    * @param a2      Additional memory allocation per attempt (in GB) after the first attempt
    *
    * @return  The escalated memory size in GB, taking into account the task attempt number and input size.
    */

    // predict peak mem
    peak_mem_pred = linear_regression_fit(input_size_GB,b0,b1)
    //println("${peak_mem_pred}, ${input_size_GB}, ${b0}, ${b1}")

    // if second try, add multiply predicted by factor 1 (f1)
    if (task.attempt == 2){
        return "${peak_mem_pred * f1} GB"
    }

    // if second attempt, add a2 gb to previous attempt  
    if (task.attempt == 3){
        return "${(peak_mem_pred * f1) + a2} GB"
    }

    // keep adding a2 gb for each attempt
    if (task.attempt > 3) {
        return "${(peak_mem_pred * f1) + ((task.attempt) * a2)}"
    }

    // if first try, use linear regression
    return "${peak_mem_pred} GB"
}

process {
    errorStrategy = {retry_strategy(task, params.max_attempts, params.default_error_strategy) }
    max_retries = params.max_attempts
    
    withLabel:mem_k2r_escalate{
        //memory = "2 GB"
        
        memory = {k2r_escalate_memory_strategy(
                            task,
                            bytesToSize(meta.fqs_total_size, "GB"),
                            params.mem_k2r_b0_final,
                            params.mem_k2r_b1,
                            params.mem_k2r_f1,
                            params.mem_k2r_a2)}
        
    }
    
}
